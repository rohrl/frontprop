{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This notebook implements a basic neuron using a modified signal. i.e. instead of calculating signal as:\n",
    "\n",
    "`signal = 1/mean_squared_error(neuron_weights, input_pattern)`\n",
    "\n",
    "The InvertedNeuron calculates it as \n",
    "\n",
    "`signal = mean_squared_error(neuron_weights, input_pattern)`\n",
    "\n",
    "This only required a slight modification in the weight and threshold update logic. The most notable difference being the Neuron now activates when `signal <= threshold` instead of when `signal >= threshold` which makes threshold an upper bound rather than a lower bound.\n",
    "\n",
    "The main motivation for the InvertedNeuron is efficiency. The original Neuron required a threshold which could approach infinity. This is very inefficient and does not scale well to large datasets since the threshold grows proportionally to the size of the dataset.\n",
    "\n",
    "Additionally, the InvertedNeuron experiments with using smaller, more efficient datatypes such as `np.float16`.\n",
    "Currently the improvements offered by the InvertedNeuron are backed only by intuition. More work needs to be done to compare the InvertedNeuron to the original Neuron.\n",
    "\n",
    "\n",
    "### Update After Comparison to the original Neuron\n",
    "The InvertedNeuron did not offer the expected space improvement. This is due to the original Neuron using floating point values to avoid storing large integers.\n",
    "The InvertedNeuron is potentially still worth pursuing as it has arguably simpler activation logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from InvertedNeuron import InvertedNeuron, OriginalNeuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "\n",
    "# plot the 2D matrix heatmap\n",
    "# supports a 2D array, or flattened (uses DIMS to restore 1D to 2D)\n",
    "def plot_matrix(dims, *datas):\n",
    "    PLOTS_PER_ROW = 20\n",
    "    cols = min(len(datas), PLOTS_PER_ROW)\n",
    "    rows = math.ceil(len(datas)/PLOTS_PER_ROW)\n",
    "    fig = plt.figure(figsize=(cols,rows))\n",
    "    for i, data in enumerate(datas):\n",
    "        if data.shape != dims:\n",
    "            data = np.reshape(data, dims)\n",
    "        fig.add_subplot(rows, cols, i+1)\n",
    "        plt.imshow(data, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        # plt.title(f\"#{i}\")\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input patterns\n",
    "\n",
    "DIMS = [7,7]\n",
    "\n",
    "patterns = np.array([\n",
    "    np.array([\n",
    "        [1,0,0,0,0,0,1],\n",
    "        [0,1,0,0,0,1,0],\n",
    "        [0,0,1,0,1,0,0],\n",
    "        [0,0,0,1,0,0,0],\n",
    "        [0,0,1,0,1,0,0],\n",
    "        [0,1,0,0,0,1,0],\n",
    "        [1,0,0,0,0,0,1]\n",
    "    ]),\n",
    "    np.array([\n",
    "        [0,0,0,1,0,0,0],\n",
    "        [0,0,0,1,0,0,0],\n",
    "        [0,0,0,1,0,0,0],\n",
    "        [1,1,1,1,1,1,1],\n",
    "        [0,0,0,1,0,0,0],\n",
    "        [0,0,0,1,0,0,0],\n",
    "        [0,0,0,1,0,0,0]\n",
    "    ]),\n",
    "    np.array([\n",
    "        [0,0,1,1,1,0,0],\n",
    "        [0,1,0,0,0,1,0],\n",
    "        [1,0,0,0,0,0,1],\n",
    "        [1,0,0,0,0,0,1],\n",
    "        [1,0,0,0,0,0,1],\n",
    "        [0,1,0,0,0,1,0],\n",
    "        [0,0,1,1,1,0,0]\n",
    "    ]),\n",
    "    np.array([\n",
    "        [0,1,0,0,0,0,0],\n",
    "        [0,1,0,0,0,0,0],\n",
    "        [0,1,0,0,0,0,0],\n",
    "        [0,1,0,0,0,0,0],\n",
    "        [0,1,0,0,0,0,0],\n",
    "        [0,1,0,0,0,0,0],\n",
    "        [0,1,0,0,0,0,0]\n",
    "    ]),\n",
    "    np.array([\n",
    "        [1,1,1,0,0,0,0],\n",
    "        [1,1,1,0,0,0,0],\n",
    "        [1,1,1,0,0,0,0],\n",
    "        [0,0,0,0,0,0,0],\n",
    "        [0,0,0,0,0,0,0],\n",
    "        [0,0,0,0,0,0,0],\n",
    "        [0,0,0,0,0,0,0]\n",
    "    ])\n",
    "# np.array([\n",
    "# [0,1,1,0],\n",
    "# [1,0,0,1],\n",
    "# [1,0,0,1],\n",
    "# [0,1,1,0]\n",
    "# ])\n",
    "])\n",
    "\n",
    "# Define probabilities\n",
    "\n",
    "probs = np.full(len(patterns), 1) # np.array([0.43 0.43 0.13])\n",
    "probs = probs / probs.sum()\n",
    "\n",
    "def randomly_choose_input_idx(iteration):\n",
    "    return np.random.choice(len(probs), p=probs)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InvertedNeuron Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------\n",
      "Running frontprop on following patterns:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAA+CAYAAABtAQ2bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAABh0lEQVR4nO3cwY6CMBRAUTvx/3+Z2c6GYhiLV3LO1oVQ4k1jn45t2x4AFT+fvgCAv0QJSBElIEWUgBRRAlJECUh5Hry+Oy8wxnjzpZx3MNZweKFjjLfPRcyuacXabdu27D5XjI2cXYOj+5zd49XP5KxXnuVj8tk86+o12LtPOyUgRZSAFFECUkQJSBElIGV6+jb7Nv4Dp0un3s8Pjl/zLc+T+7NTAlJECUgRJSBFlIAUUQJSRAlIOfpB7q4V4wKOidcqra8xDvbYKQEpogSkiBKQIkpAiigBKaIEpJweCZj5tmP/q4+gHXnzX3cekbFTAlJECUgRJSBFlIAUUQJSRAlIWTIS8G3/EnCHP8Y3ZsBd2CkBKaIEpIgSkCJKQIooASmiBKScHglYceRdHBe4k9L6rhgb4R7slIAUUQJSRAlIESUgRZSAFFECUqYjAaVjeMfEa129vsY42GOnBKSIEpAiSkCKKAEpogSkiBKQMhynAyV2SkCKKAEpogSkiBKQIkpAiigBKb9iE2uMVp1N/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 360x72 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with probabilities:\n",
      "[0.20 0.20 0.20 0.20 0.20]\n",
      " ... and noise prob 0\n",
      "\n",
      "\n",
      "\n",
      " --- Iter #0 --- \n",
      "Neurons' weights:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAABz0lEQVR4nO2aLYpCYRhGx3G6WAQ3YBFMgoJBXMCNFpPRn6ZFcA0uwSYoCGLQIAgGV+AOFDRYBYuIThx48Htm2gzMOfE7vCKHF+7H5caez+cbfPH+23/gr0EQgSACQQSCCB9OTqdT+wiqVqv2x1utlvXFYjHo7ve7ne10OtYnEgnrD4dD7NU5GyIQRCCIQBCBIAJBBIII9h6y2+3s8Gw2s369Xltfq9WCLpfL2dlsNmt9PB63PgQbIhBEIIhAEIEgAkEEggj2HjIcDu3wfD63fjKZWL9arYLudrvZ2UwmY32hULD+dDq9PGdDBIIIBBEIIhBEIIhAEMHeQ0ajkR3u9/vWf3dPaTabQffd+47r9Wr9eDy2PgQbIhBEIIhAEIEgAkEE+9htt9t2OJlMWr/ZbKw/Ho9BVy6X7exgMLC+2+1av91uX56zIQJBBIIIBBEIIhBEIIgQcx//LxYL+1lmPp+3P97r9axPp9NBdz6f7WypVLI+lUpZH0URn2X+BIIIBBEIIhBEIIhAEMG+D9nv93b4crlYv1wura9UKkH3eDzsbL1et77RaFgfRdHLczZEIIhAEIEgAkEEgggEEez7kP8IGyIQRCCIQBCBIAJBhE8UmV8L0d/FbAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67 1.00 0.43 0.63 0.62 0.08 0.13 0.49 0.36 0.10 0.77 0.94 0.78 0.80\n",
      " 0.11 0.78 0.02 0.50 0.74 0.89 0.12 0.74 0.28 0.69 0.12 0.66 0.70 0.76\n",
      " 0.17 0.24 0.44 0.99 0.25 0.79 0.25 0.71 0.90 0.38 0.48 0.39 0.61 0.70\n",
      " 0.59 0.65 0.10 0.35 0.34 0.98 0.40] float16\n",
      "Layer outputs:\n",
      "12.49\n",
      "Threshold:\n",
      "1.005 float16\n",
      "\n",
      " --- Iter #500 --- \n",
      "Neurons' weights:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAABz0lEQVR4nO2aLYpCYRhGx3G6WAQ3YBFMgoJBXMCNFpPRn6ZFcA0uwSYoCGLQIAgGV+AOFDRYBYuIThx48Htm2gzMOfE7vCKHF+7H5caez+cbfPH+23/gr0EQgSACQQSCCB9OTqdT+wiqVqv2x1utlvXFYjHo7ve7ne10OtYnEgnrD4dD7NU5GyIQRCCIQBCBIAJBBIII9h6y2+3s8Gw2s369Xltfq9WCLpfL2dlsNmt9PB63PgQbIhBEIIhAEIEgAkEEggj2HjIcDu3wfD63fjKZWL9arYLudrvZ2UwmY32hULD+dDq9PGdDBIIIBBEIIhBEIIhAEMHeQ0ajkR3u9/vWf3dPaTabQffd+47r9Wr9eDy2PgQbIhBEIIhAEIEgAkEE+9htt9t2OJlMWr/ZbKw/Ho9BVy6X7exgMLC+2+1av91uX56zIQJBBIIIBBEIIhBEIIgQcx//LxYL+1lmPp+3P97r9axPp9NBdz6f7WypVLI+lUpZH0URn2X+BIIIBBEIIhBEIIhAEMG+D9nv93b4crlYv1wura9UKkH3eDzsbL1et77RaFgfRdHLczZEIIhAEIEgAkEEgggEEez7kP8IGyIQRCCIQBCBIAJBhE8UmV8L0d/FbAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67 1.00 0.43 0.63 0.62 0.08 0.13 0.49 0.36 0.10 0.77 0.94 0.78 0.80\n",
      " 0.11 0.78 0.02 0.50 0.74 0.89 0.12 0.74 0.28 0.69 0.12 0.66 0.70 0.76\n",
      " 0.17 0.24 0.44 0.99 0.25 0.79 0.25 0.71 0.90 0.38 0.48 0.39 0.61 0.70\n",
      " 0.59 0.65 0.10 0.35 0.34 0.98 0.40] float16\n",
      "Layer outputs:\n",
      "12.49\n",
      "Threshold:\n",
      "11.36 float16\n",
      "\n",
      " --- Iter #1000 --- \n",
      "Neurons' weights:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAABDklEQVR4nO3asQqDQBAA0WxIZe3/f6GttpcqBIa4a3KKQua1B/EYDlyPRGvtprf72Ru4GoOAQcAgYBB4FOvpKygidtzKvoZhSNfnef64eU8IGAQMAgYBg4BBwCCQziHVnDGOY7o+TdP3O9qomjOWZfnpdz0hYBAwCBgEDAIGAYNAZLfuEdF1Jd8zKxw1Z7y01rwP2cIgYBAwCBgEDAIGgUPnkEo2a/TOGRXnkI0MAgYBg4BBwCBQ/R2iy5U//9d4QsAgYBAwCBgEDAIGga7P/7NmhT2e7ef/RgYBg4BBwCBgEDAIpPchZ84ZlerZ1d7XeELAIGAQMAgYBAwCBoH0PuQfeULAIGAQMAgYBAwCT/UlQIB3ewz0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.23 0.01 0.00 0.01 0.00 0.00 0.98 0.00 1.95 0.00 0.01 0.01 0.98 0.01\n",
      " 0.00 0.01 0.98 0.00 0.98 0.01 0.00 0.01 0.00 0.01 0.98 0.01 0.01 0.01\n",
      " 0.00 0.00 0.98 0.01 0.98 0.01 0.00 0.01 0.98 0.00 0.00 0.00 0.98 0.01\n",
      " 0.98 0.01 0.00 0.00 0.00 0.01 0.98] float16\n",
      "Layer outputs:\n",
      "0.01215\n",
      "Threshold:\n",
      "0.012215 float16\n",
      "\n",
      " --- Iter #1500 --- \n",
      "Neurons' weights:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAABDklEQVR4nO3asQqDQBAA0WxIZe3/f6GttpcqBIa4a3KKQua1B/EYDlyPRGvtprf72Ru4GoOAQcAgYBB4FOvpKygidtzKvoZhSNfnef64eU8IGAQMAgYBg4BBwCCQziHVnDGOY7o+TdP3O9qomjOWZfnpdz0hYBAwCBgEDAIGAYNAZLfuEdF1Jd8zKxw1Z7y01rwP2cIgYBAwCBgEDAIGgUPnkEo2a/TOGRXnkI0MAgYBg4BBwCBQ/R2iy5U//9d4QsAgYBAwCBgEDAIGga7P/7NmhT2e7ef/RgYBg4BBwCBgEDAIpPchZ84ZlerZ1d7XeELAIGAQMAgYBAwCBoH0PuQfeULAIGAQMAgYBAwCT/UlQIB3ewz0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.23 0.00 0.00 0.00 0.00 0.00 0.98 0.00 1.95 0.00 0.00 0.00 0.98 0.00\n",
      " 0.00 0.00 0.98 0.00 0.98 0.00 0.00 0.00 0.00 0.00 0.98 0.00 0.00 0.00\n",
      " 0.00 0.00 0.98 0.00 0.98 0.00 0.00 0.00 0.98 0.00 0.00 0.00 0.98 0.00\n",
      " 0.98 0.00 0.00 0.00 0.00 0.00 0.98] float16\n",
      "Layer outputs:\n",
      "0.01214\n",
      "Threshold:\n",
      "0.0122 float16\n"
     ]
    }
   ],
   "source": [
    "ITERS = 2000\n",
    "VERBOSE = False\n",
    "DRAW_INTERVAL = 500\n",
    "# Throw in some noise inputs \n",
    "# (without noise at zero, it converges very quickly - noise rate increases slows down learning exponentially!)\n",
    "NOISE_INPUTS_PROB = 0 # 0.02\n",
    "\n",
    "neuron = InvertedNeuron(DIMS,  0.005,  0.01)\n",
    "\n",
    "print(\"\\n----------------\\nRunning frontprop on following patterns:\")\n",
    "plot_matrix(DIMS, *patterns)\n",
    "print(f\"with probabilities:\\n{probs}\\n ... and noise prob {NOISE_INPUTS_PROB}\\n\\n\")\n",
    "\n",
    "for i in range(ITERS):\n",
    "    \n",
    "    if np.random.rand() < NOISE_INPUTS_PROB:\n",
    "        input = np.random.rand(*DIMS).flatten()\n",
    "    else:\n",
    "        input_idx = randomly_choose_input_idx(i)\n",
    "        input = patterns[input_idx].flatten()\n",
    "    input = np.array([\n",
    "        [25,0,0,0,0,0,1],\n",
    "        [0,2,0,0,0,1,0],\n",
    "        [0,0,1,0,1,0,0],\n",
    "        [0,0,0,1,0,0,0],\n",
    "        [0,0,1,0,1,0,0],\n",
    "        [0,1,0,0,0,1,0],\n",
    "        [1,0,0,0,0,0,1]]).flatten()\n",
    "    if VERBOSE:\n",
    "        print(f\"Iter #{i}: Feeding input pattern #{input_idx}\")\n",
    "        print(input)\n",
    "        plot_matrix(input)\n",
    "        \n",
    "    out = neuron.forward(input)\n",
    "    \n",
    "    if i % DRAW_INTERVAL == 0:\n",
    "        print(f\"\\n --- Iter #{i} --- \")\n",
    "        print(\"Neurons' weights:\")\n",
    "        plot_matrix(neuron.dims, neuron.W)\n",
    "        print(neuron.W, neuron.W.dtype)\n",
    "        print(\"Layer outputs:\")\n",
    "        print(out)\n",
    "        print(\"Threshold:\")\n",
    "        print(neuron.t, neuron.t.dtype)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of InvertedNeuron to OriginalNeuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------\n",
      "Running frontprop on following pattern:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAA40lEQVR4nO3aQWrDMBRAwSj0/ldWl4VHKoUK45bObI3i8BDoYzTmnA++PO/+A7+NICFICBKCxMfq4Rjj6Ai68gQbYxytn3O+/AE7JAQJQUKQECQECUFiOYfs7OaM01nhjnfbISFICBKChCAhSAgSY3OeLx9eOWeceuNbjO8h7xAkBAlBQpAQJAQJQUKQECQECUFCkBAkBAlBQpAQJAQJQUKQECR21zKXi//ydYjv1tshIUgIEoKEICFICBJH1zJP55Qr3/1TdkgIEoKEICFICBKCxO5a5r9jh4QgIUgIEoKEIPEJT8omiOle2kQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvertedNeuron threshold: \t\t\t0.00018787384033203125\n",
      "Size of InvertedNeuron threshold: \t\t26 bytes\n",
      "Elapsed execution time of InvertedNeuron: \t13.354985237121582 seconds\n",
      "OriginalNeuron threshold: \t\t\t9.888688802260371e+28\n",
      "Size of OriginalNeuron threshold: \t\t32 bytes\n",
      "Elapsed execution time of OriginalNeuron: \t11.46970009803772 seconds\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "import time\n",
    "\n",
    "ITERS = 80000\n",
    "DRAW_INTERVAL = ITERS-1\n",
    "# Throw in some noise inputs \n",
    "# (without noise at zero, it converges very quickly - noise rate increases slows down learning exponentially!)\n",
    "NOISE_INPUTS_PROB = 0 # 0.02\n",
    "\n",
    "inverted_neuron = InvertedNeuron(DIMS,  0.005,  0.01)\n",
    "original_neuron = OriginalNeuron(DIMS,  0.005,  0.01)\n",
    "\n",
    "pattern = np.array([\n",
    "        [0,0,1,1,1,0,0],\n",
    "        [0,1,0,0,0,1,0],\n",
    "        [1,0,0,0,0,0,1],\n",
    "        [1,0,0,0,0,0,1],\n",
    "        [1,0,0,0,0,0,1],\n",
    "        [0,1,0,0,0,1,0],\n",
    "        [0,0,1,1,1,0,0]]).flatten()\n",
    "\n",
    "print(\"\\n----------------\\nRunning frontprop on following pattern:\")\n",
    "plot_matrix(DIMS, pattern)\n",
    "\n",
    "original_neuron_start_time = time.time()\n",
    "\n",
    "for _ in range(ITERS):\n",
    "    original_out = original_neuron.forward(pattern)\n",
    "    \n",
    "original_neuron_end_time = time.time()\n",
    "\n",
    "inverted_neuron_start_time = time.time()\n",
    "\n",
    "for _ in range(ITERS):\n",
    "    inverted_out = inverted_neuron.forward(pattern)\n",
    "    \n",
    "inverted_neuron_end_time = time.time()\n",
    "\n",
    "inverted_neuron_elapsed_time = inverted_neuron_end_time - inverted_neuron_start_time\n",
    "original_neuron_elapsed_time = original_neuron_end_time - original_neuron_start_time\n",
    "\n",
    "# print(\"Inverted neurons' weights:\")\n",
    "# plot_matrix(inverted_neuron.dims, inverted_neuron.W)\n",
    "print(f\"InvertedNeuron threshold: \\t\\t\\t{inverted_neuron.t}\")\n",
    "print(f\"Size of InvertedNeuron threshold: \\t\\t{getsizeof(inverted_neuron.t)} bytes\")\n",
    "print(f\"Elapsed execution time of InvertedNeuron: \\t{inverted_neuron_elapsed_time} seconds\")\n",
    "\n",
    "# print(\"Original neurons' weights:\")\n",
    "# plot_matrix(original_neuron.dims, original_neuron.W)\n",
    "print(f\"OriginalNeuron threshold: \\t\\t\\t{original_neuron.t}\")\n",
    "print(f\"Size of OriginalNeuron threshold: \\t\\t{getsizeof(original_neuron.t)} bytes\")\n",
    "print(f\"Elapsed execution time of OriginalNeuron: \\t{original_neuron_elapsed_time} seconds\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Notes \n",
    "\n",
    "Let N be the length of the input vector\n",
    "\n",
    "if input/weight vector values are in [0,1] => mean_squared_error in [0, 1] => 1/mean_squared_error in [1, inf]\n",
    "\n",
    "When W highly similar to data:\n",
    "- mean_squared_error -> 0\n",
    "- signal = 1/mean_squared_error -> inf\n",
    "\n",
    "When W has zero similarity to data:\n",
    "- mean_squared_error -> 1\n",
    "- 1/mean_squared_error -> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
