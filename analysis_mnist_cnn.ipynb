{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# [WIP] Analysis of MNIST dataset using CNN build from Frontprop layers",
   "id": "674c86fbbfb0b657"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-22T11:46:31.471463Z",
     "start_time": "2024-07-22T11:46:31.442792Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:46:33.281825Z",
     "start_time": "2024-07-22T11:46:31.704785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import torch_module as fp\n",
    "from fp_utils import sphere_rnd_gen, shanon_entropy_binned, plot_matrix\n",
    "from fp_datasets import SimplePatterns"
   ],
   "id": "5e9a49099514965c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14332/3165282269.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:46:33.313677Z",
     "start_time": "2024-07-22T11:46:33.284289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ],
   "id": "ff309444acfb419c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the CPU\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:46:33.338262Z",
     "start_time": "2024-07-22T11:46:33.315367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n"
   ],
   "id": "10ac504347c6292d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load MNIST dataset",
   "id": "1755020c1cdb0e3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:46:34.576606Z",
     "start_time": "2024-07-22T11:46:33.340044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=ToTensor()\n",
    ")"
   ],
   "id": "474e01fd43144cf2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:46:34.614780Z",
     "start_time": "2024-07-22T11:46:34.578116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': torch.utils.data.DataLoader(train_data,\n",
    "                                         batch_size=100,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=1),\n",
    "\n",
    "    'test': torch.utils.data.DataLoader(test_data,\n",
    "                                        batch_size=100,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=1),\n",
    "}\n"
   ],
   "id": "74531a0c238589ba",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Frontprop CNN model ",
   "id": "c53ed1b924ee472a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:46:34.656947Z",
     "start_time": "2024-07-22T11:46:34.619090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class Fp_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Fp_CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            fp.FpConv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            fp.FpConv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = fp.FpLinear(32 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output, x  # return x for visualization"
   ],
   "id": "d1068984d062164a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:46:34.844075Z",
     "start_time": "2024-07-22T11:46:34.806606Z"
    }
   },
   "cell_type": "code",
   "source": "fp_cnn = Fp_CNN()",
   "id": "825bb0aab24aa611",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:46:35.422530Z",
     "start_time": "2024-07-22T11:46:35.386194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def train_fp(num_epochs, cnn, loaders):\n",
    "    cnn.train()\n",
    "\n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (images, labels) in enumerate(loaders['train']):\n",
    "\n",
    "                # gives batch data, normalize x when iterate train_loader\n",
    "                b_x = Variable(images)  # batch x\n",
    "\n",
    "                output = cnn(b_x)[0]\n",
    "\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print('Epoch [{}/{}], Step [{}/{}], Loss: --'\n",
    "                          .format(epoch + 1, num_epochs, i + 1, total_step))"
   ],
   "id": "2cca498ee1fb4e19",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:46:46.673356Z",
     "start_time": "2024-07-22T11:46:36.559222Z"
    }
   },
   "cell_type": "code",
   "source": "train_fp(1, fp_cnn, loaders)",
   "id": "ded6c5201c14e315",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain_fp\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp_cnn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloaders\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[9], line 14\u001B[0m, in \u001B[0;36mtrain_fp\u001B[0;34m(num_epochs, cnn, loaders)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (images, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(loaders[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m     10\u001B[0m \n\u001B[1;32m     11\u001B[0m     \u001B[38;5;66;03m# gives batch data, normalize x when iterate train_loader\u001B[39;00m\n\u001B[1;32m     12\u001B[0m     b_x \u001B[38;5;241m=\u001B[39m Variable(images)  \u001B[38;5;66;03m# batch x\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mcnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb_x\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28mprint\u001B[39m(output)\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[7], line 23\u001B[0m, in \u001B[0;36mFp_CNN.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 23\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x)  \u001B[38;5;66;03m# flatten the output of conv2 to (batch_size, 32 * 7 * 7)\u001B[39;00m\n\u001B[1;32m     25\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mview(x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/work/code/frontprop/torch_module/FpConv2d.py:90\u001B[0m, in \u001B[0;36mFpConv2d.forward\u001B[0;34m(self, mini_batch)\u001B[0m\n\u001B[1;32m     87\u001B[0m outputs \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sample \u001B[38;5;129;01min\u001B[39;00m mini_batch:\n\u001B[0;32m---> 90\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     91\u001B[0m     outputs\u001B[38;5;241m.\u001B[39mappend(out)\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mstack(outputs)\n",
      "File \u001B[0;32m~/work/code/frontprop/torch_module/FpConv2d.py:203\u001B[0m, in \u001B[0;36mFpConv2d.forward_single\u001B[0;34m(self, sample)\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight[kernel_idx] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_weights_boost(kernel_idx, data_tensor_normd)\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;66;03m# normalise weights\u001B[39;00m\n\u001B[0;32m--> 203\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight[kernel_idx] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__normalise_unitary\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkernel_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight[kernel_idx]\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_channels, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel_size)\n\u001B[1;32m    206\u001B[0m \u001B[38;5;66;03m# Update thresholds:\u001B[39;00m\n",
      "File \u001B[0;32m~/work/code/frontprop/torch_module/FpConv2d.py:59\u001B[0m, in \u001B[0;36mFpConv2d.__normalise_unitary\u001B[0;34m(self, data, dim)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__normalise_unitary\u001B[39m(\u001B[38;5;28mself\u001B[39m, data, dim):\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data \u001B[38;5;241m/\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/functional.py:1615\u001B[0m, in \u001B[0;36mnorm\u001B[0;34m(input, p, dim, keepdim, out, dtype)\u001B[0m\n\u001B[1;32m   1613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m p \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfro\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m (dim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dim, (\u001B[38;5;28mint\u001B[39m, torch\u001B[38;5;241m.\u001B[39mSymInt)) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(dim) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m   1614\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1615\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinalg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvector_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1616\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1617\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mvector_norm(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m2\u001B[39m, _dim, keepdim, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train backprop for comparison",
   "id": "707fd91926d2ac98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:33:57.990937Z",
     "start_time": "2024-07-22T11:33:57.953036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )  # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)  # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output, x  # return x for visualization"
   ],
   "id": "21a435d723b0e2c0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:33:59.122742Z",
     "start_time": "2024-07-22T11:33:59.084041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn = CNN()\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.01)"
   ],
   "id": "6ad00cf32ffb47f2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:33:59.949228Z",
     "start_time": "2024-07-22T11:33:59.945864Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bf679c1368756eb",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:34:04.719750Z",
     "start_time": "2024-07-22T11:34:00.386563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "def train(num_epochs, cnn, loaders):\n",
    "    cnn.train()\n",
    "\n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "\n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(images)  # batch x\n",
    "            b_y = Variable(labels)  # batch y\n",
    "\n",
    "            output = cnn(b_x)[0]\n",
    "            loss = loss_func(output, b_y)\n",
    "\n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()  # apply gradients             \n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "                pass\n",
    "\n",
    "        pass\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "train(num_epochs, cnn, loaders)"
   ],
   "id": "2f0ac17937b8c090",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 39\u001B[0m\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcnn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloaders\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[13], line 26\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(num_epochs, cnn, loaders)\u001B[0m\n\u001B[1;32m     23\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# backpropagation, compute gradients \u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# apply gradients             \u001B[39;00m\n\u001B[1;32m     27\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    524\u001B[0m     )\n\u001B[0;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def test():\n",
    "    # Test the model\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in loaders['test']:\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "            pass\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "test()"
   ],
   "id": "b02832085276b04c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n"
   ],
   "id": "5e62631c4574f45b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e28efaeb5ec01860"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
