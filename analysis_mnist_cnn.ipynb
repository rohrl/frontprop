{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# [WIP] Analysis of MNIST dataset using CNN build from Frontprop layers\n",
    "This is still work in progress..."
   ],
   "id": "674c86fbbfb0b657"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-15T05:02:25.768919Z",
     "start_time": "2025-01-15T05:02:25.753851Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:02:26.683985Z",
     "start_time": "2025-01-15T05:02:26.665763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import fp_modules as fp\n",
    "from utils.fp_utils import sphere_rnd_gen, shanon_entropy_binned, plot_matrix\n",
    "from utils.fp_datasets import SimplePatterns"
   ],
   "id": "5e9a49099514965c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:02:28.100044Z",
     "start_time": "2025-01-15T05:02:27.979037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ],
   "id": "ff309444acfb419c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the CPU\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:02:28.776853Z",
     "start_time": "2025-01-15T05:02:28.753090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Disable gradients in torch - Frontprop does not need them.\n",
    "torch.set_grad_enabled(False)"
   ],
   "id": "30ca77390ff7fe84",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f5b1d66ab20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:02:29.715050Z",
     "start_time": "2025-01-15T05:02:29.696422Z"
    }
   },
   "cell_type": "code",
   "source": "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})",
   "id": "10ac504347c6292d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1755020c1cdb0e3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:02:32.135732Z",
     "start_time": "2025-01-15T05:02:31.593234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=ToTensor()\n",
    ")"
   ],
   "id": "474e01fd43144cf2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:02:33.405558Z",
     "start_time": "2025-01-15T05:02:33.385812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': torch.utils.data.DataLoader(train_data,\n",
    "                                         batch_size=100,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=1),\n",
    "\n",
    "    'test': torch.utils.data.DataLoader(test_data,\n",
    "                                        batch_size=100,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=1),\n",
    "}\n"
   ],
   "id": "74531a0c238589ba",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Frontprop CNN model ",
   "id": "c53ed1b924ee472a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:02:35.123290Z",
     "start_time": "2025-01-15T05:02:35.099531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class Fp_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Fp_CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            fp.FpConv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            fp.FpConv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = fp.FpLinear(32 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output, x  # return x for visualization"
   ],
   "id": "d1068984d062164a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:02:36.297790Z",
     "start_time": "2025-01-15T05:02:36.277907Z"
    }
   },
   "cell_type": "code",
   "source": "fp_cnn = Fp_CNN()",
   "id": "825bb0aab24aa611",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:02:37.207959Z",
     "start_time": "2025-01-15T05:02:37.187813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def train_fp(num_epochs, cnn, loaders):\n",
    "    cnn.train()\n",
    "\n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (images, labels) in enumerate(loaders['train']):\n",
    "\n",
    "                # gives batch data, normalize x when iterate train_loader\n",
    "                b_x = Variable(images)  # batch x\n",
    "\n",
    "                output = cnn(b_x)[0]\n",
    "\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print('Epoch [{}/{}], Step [{}/{}], Loss: --'\n",
    "                          .format(epoch + 1, num_epochs, i + 1, total_step))"
   ],
   "id": "2cca498ee1fb4e19",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:20:09.953719Z",
     "start_time": "2025-01-15T05:02:38.430918Z"
    }
   },
   "cell_type": "code",
   "source": "train_fp(1, fp_cnn, loaders)",
   "id": "ded6c5201c14e315",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/600], Loss: --\n",
      "Epoch [1/1], Step [200/600], Loss: --\n",
      "Epoch [1/1], Step [300/600], Loss: --\n",
      "Epoch [1/1], Step [400/600], Loss: --\n",
      "Epoch [1/1], Step [500/600], Loss: --\n",
      "Epoch [1/1], Step [600/600], Loss: --\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train backprop for comparison",
   "id": "707fd91926d2ac98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:33:57.990937Z",
     "start_time": "2024-07-22T11:33:57.953036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )  # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)  # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output, x  # return x for visualization"
   ],
   "id": "21a435d723b0e2c0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:33:59.122742Z",
     "start_time": "2024-07-22T11:33:59.084041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn = CNN()\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.01)"
   ],
   "id": "6ad00cf32ffb47f2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:33:59.949228Z",
     "start_time": "2024-07-22T11:33:59.945864Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bf679c1368756eb",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T11:34:04.719750Z",
     "start_time": "2024-07-22T11:34:00.386563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "def train(num_epochs, cnn, loaders):\n",
    "    cnn.train()\n",
    "\n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "\n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(images)  # batch x\n",
    "            b_y = Variable(labels)  # batch y\n",
    "\n",
    "            output = cnn(b_x)[0]\n",
    "            loss = loss_func(output, b_y)\n",
    "\n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()  # apply gradients             \n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "                pass\n",
    "\n",
    "        pass\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "train(num_epochs, cnn, loaders)"
   ],
   "id": "2f0ac17937b8c090",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 39\u001B[0m\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcnn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloaders\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[13], line 26\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(num_epochs, cnn, loaders)\u001B[0m\n\u001B[1;32m     23\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# backpropagation, compute gradients \u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# apply gradients             \u001B[39;00m\n\u001B[1;32m     27\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    524\u001B[0m     )\n\u001B[0;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/code/frontprop/venv-p3.12/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def test():\n",
    "    # Test the model\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in loaders['test']:\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "            pass\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "test()"
   ],
   "id": "b02832085276b04c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n"
   ],
   "id": "5e62631c4574f45b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e28efaeb5ec01860"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
