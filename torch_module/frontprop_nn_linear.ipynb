{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611aa295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karol\\AppData\\Local\\Temp\\ipykernel_4564\\1437536937.py:12: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffddd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e204b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "T_DECAY_DEFAULT = 0.0005\n",
    "W_BOOST_DEFAULT = 0.02\n",
    "\n",
    "class FpLinear(nn.Linear):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True, t_decay=T_DECAY_DEFAULT, w_boost=W_BOOST_DEFAULT):\n",
    "        if bias:\n",
    "            raise Exception(\"Bias not supported for FrontPropLinear\")\n",
    "        \n",
    "        super(FpLinear, self).__init__(in_features, out_features, bias=False)\n",
    "\n",
    "        # learning is through front propagation only\n",
    "        self.weight.requires_grad = False\n",
    "\n",
    "        # init using Gaussian\n",
    "        nn.init.normal_(self.weight, mean=0, std=1)\n",
    "\n",
    "        # hyper params\n",
    "        self.t_decay = t_decay\n",
    "        self.w_boost = w_boost\n",
    "\n",
    "        self.frozen = False\n",
    "\n",
    "        assert self.t_decay > 0        \n",
    "        assert self.w_boost > 0\n",
    "\n",
    "        # init thresholds\n",
    "        self.t = torch.ones(self.out_features, device=self.device, dtype=self.weight.dtype)\n",
    "    \n",
    "\n",
    "    def __normalise_unitary(self, data):\n",
    "        return data / torch.norm(data, dim=1, keepdim=True)\n",
    "    \n",
    "\n",
    "    def __get_weights_boost(self, data_vector):\n",
    "        assert data_vector.shape == self.weight.shape\n",
    "\n",
    "        w_boost = self.w_boost * (data_vector - self.weight)\n",
    "        excited_filter = self.excitations.unsqueeze(1).expand_as(self.weight)\n",
    "        w_boost = w_boost * excited_filter\n",
    "\n",
    "        assert w_boost.shape == self.weight.shape\n",
    "        return w_boost\n",
    "    \n",
    "\n",
    "    def forward_single_sample(self, data):\n",
    "        \n",
    "        data_vector = data.expand(self.out_features, -1)\n",
    "        data_vector = self.__normalise_unitary(data_vector)\n",
    "\n",
    "        output = torch.sum(data_vector * self.weight, dim=1)\n",
    "\n",
    "        assert torch.all(output > -1.01) and torch.all(output < 1.01)\n",
    "\n",
    "        excitations = (output >= self.t).float()\n",
    "\n",
    "        if not self.frozen:\n",
    "            self.weight = self.weight + self.__get_weights_boost(data_vector)\n",
    "            self.weight = self.__normalise_unitary(self.weight)\n",
    "            self.t = excitations * output + (1.0 - excitations) * self.t\n",
    "            self.t = self.t * (1.0 - self.t_decay)\n",
    "\n",
    "        # output = self.__normalise_unitary(output)\n",
    "        # Output should already be normalised\n",
    "        assert torch.all_close(torch.norm(output, dim=1), torch.ones(self.out_features), atol=1e-3) \n",
    "        \n",
    "        self.__assert()\n",
    "        \n",
    "        return output\n",
    "    \n",
    "\n",
    "    def forward(self, input):\n",
    "        # FIXME:\n",
    "        # As of now, samples are just processed sequentially, for simplicity.\n",
    "\n",
    "        assert input.shape == (input.shape[0], self.in_features)\n",
    "\n",
    "        for i, sample in enumerate(input):\n",
    "            sample_out = self.forward_single_sample(sample)\n",
    "            self.output[i] = sample_out\n",
    "\n",
    "        assert self.output.shape == (input.shape[0], self.out_features)\n",
    "    \n",
    "        # ReLU-like non-linear transformation via cutoff threshold\n",
    "        #\n",
    "        #   TODO: Should we output the absolute value or only the diff above threshold ?\n",
    "        #   (note the threshold changes on each pass)\n",
    "        self.output = torch.where(self.output >= self.t, self.output - self.t, torch.zeros_like(self.output))\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        raise Exception(\"Backward pass not implemented for FrontPropConv2d\")\n",
    "\n",
    "\n",
    "    def freeze(self):\n",
    "        self.frozen = True\n",
    "            \n",
    "\n",
    "    def unfreeze(self):\n",
    "        self.frozen = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e668ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ch = 3\n",
    "out_ch = 5\n",
    "kernel_size = 2\n",
    "stride = 1\n",
    "\n",
    "conv2d = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28558ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "img_w = 16\n",
    "img_h = 16\n",
    "\n",
    "# 3 channels, 16x16 image\n",
    "x = torch.rand((batch_size, in_ch, img_w, img_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fea2306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  1],\n",
       "        [ 0,  0,  0,  2],\n",
       "        ...,\n",
       "        [ 9,  2, 15, 13],\n",
       "        [ 9,  2, 15, 14],\n",
       "        [ 9,  2, 15, 15]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "275d091a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True],\n",
       "        [ True,  True,  True, False],\n",
       "        [ True,  True,  True, False],\n",
       "        ...,\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~(torch.nonzero(x) > 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52f95422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out_ch x in_ch x kernel_size x kernel_size\n",
    "conv2d.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba46bf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out_ch\n",
    "conv2d.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4f01608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 15, 15])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size x out_ch x img_w x img_h\n",
    "out = conv2d(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc52ad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 15, 15, 2, 2])\n",
      "15 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 30, 30])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches = x.unfold(2, kernel_size, stride).unfold(3, kernel_size, stride)\n",
    "print(patches.shape)\n",
    "\n",
    "# Get output shape\n",
    "out_height, out_width = out.shape[-2:]\n",
    "print(out_height, out_width)\n",
    "\n",
    "# Reshape and permute patches to get exploded output\n",
    "exploded_output = patches.contiguous().view(batch_size, in_ch, out_height * kernel_size, out_width * kernel_size)\n",
    "exploded_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6bf2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e392e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to C:\\Users\\karol/.cache\\torch\\hub\\v0.10.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\karol/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:04<00:00, 9.98MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41061f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
